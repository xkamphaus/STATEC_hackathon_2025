{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4841d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import googlemaps\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "API_KEY = \"AIzaSyDjifOa--9xZsxl7V5QHKcZTaFvu5WRW3k\"  # Replace with your valid Google Maps API key\n",
    "\n",
    "# === PATHS === \n",
    "input_pdf = r\"../manual_data_imports/Releve-des-services-agrees-pour-personnes-agees-ACC.pdf\" #the data of the Ministry of Family is unfortunately only available in a pdf document. This might change in the future.\n",
    "output_folder = r\"../assets\"\n",
    "\n",
    "# === CREATE OUTPUT DIRECTORY ===\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# === SECTION MAPPING ===\n",
    "section_map = {\n",
    "    1: \"Structures d'hÃ©bergement\",\n",
    "    2: \"Logements encadrÃ©s\",\n",
    "    3: \"Centres de jour\",\n",
    "    4: \"Clubs Aktiv Plus\",\n",
    "    5: \"Services Aide et Soins Ã  domicile\",  # This section will be omitted\n",
    "    6: \"Services repas sur roues\",\n",
    "    7: \"Services tÃ©lÃ©alarme\",\n",
    "    8: \"Services activitÃ©s seniors\"\n",
    "}\n",
    "\n",
    "data = []\n",
    "current_type = \"Unknown\"  # Tracks section type (HÃ©bergement, Centre de jour, etc.)\n",
    "\n",
    "# === EXTRACT TEXT FROM PDF ===\n",
    "with pdfplumber.open(input_pdf) as pdf:\n",
    "    for page_num, page in enumerate(pdf.pages, start=1):\n",
    "        text = page.extract_text()\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # Normalize text\n",
    "        text = (\n",
    "            text.replace('\\u2019', \"'\")\n",
    "                .replace('\\u2013', '-')\n",
    "                .replace('\\u2014', '-')\n",
    "                .replace('\\xa0', ' ')\n",
    "        )\n",
    "        text = text.encode('latin1', errors='ignore').decode('utf-8', errors='ignore')\n",
    "\n",
    "        # Detect current section type\n",
    "        if re.search(r'Centres?\\s+de\\s+jour', text, flags=re.IGNORECASE):\n",
    "            current_type = \"Centre de jour\"\n",
    "        elif re.search(r'Structures?\\s+d[â€™\\'`]?hÃ©bergement', text, flags=re.IGNORECASE):\n",
    "            current_type = \"HÃ©bergement\"\n",
    "\n",
    "        # Split entries like \"1.1\", \"2.3\", etc.\n",
    "        entries = re.split(r'\\n(?=\\d+\\.\\d+\\s+)', text)\n",
    "\n",
    "        for entry in entries:\n",
    "            entry = entry.strip()\n",
    "            if not entry or not re.match(r'^\\d+\\.\\d+', entry):\n",
    "                continue\n",
    "\n",
    "            numero_match = re.match(r'^(\\d+)\\.(\\d+)', entry)\n",
    "            if not numero_match:\n",
    "                continue\n",
    "\n",
    "            section_number = int(numero_match.group(1))\n",
    "            if section_number == 5:\n",
    "                continue  # Skip section 5\n",
    "\n",
    "            numero = numero_match.group(0).strip()\n",
    "            section_name = section_map.get(section_number, \"\")\n",
    "\n",
    "            # === Name ===\n",
    "            name_match = re.match(r'^\\d+\\.\\d+\\s+([A-ZÃ‰ÃˆÃ€].+)', entry)\n",
    "            name = name_match.group(1).split('\\n')[0].strip() if name_match else \"\"\n",
    "            if \" - \" in name:\n",
    "                name = name.split(\" - \", 1)[1].strip()\n",
    "\n",
    "            # === City ===\n",
    "            ville_match = re.search(r'L-\\d{4}\\s+([A-ZÃ‰ÃˆÃ€a-z\\-]+)', entry)\n",
    "            ville = ville_match.group(1).strip() if ville_match else \"\"\n",
    "\n",
    "            # === Address ===\n",
    "            lines = entry.split('\\n')\n",
    "            address = \"\"\n",
    "            for i, line in enumerate(lines):\n",
    "                if re.match(r'L-\\d{4}\\s+[A-ZÃ‰ÃˆÃ€a-z\\-]+', line.strip()):\n",
    "                    if i > 0:\n",
    "                        address = lines[i - 1].strip() + \", \" + line.strip()\n",
    "                    else:\n",
    "                        address = line.strip()\n",
    "                    break\n",
    "\n",
    "            # === Email ===\n",
    "            email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', entry)\n",
    "            email = email_match.group(0).strip() if email_match else \"\"\n",
    "\n",
    "            # === Website ===\n",
    "            web_match = re.findall(r'(www\\.[\\w\\.-]+)', entry)\n",
    "            website = \"; \".join(web_match) if web_match else \"\"\n",
    "\n",
    "            # === Capacity ===\n",
    "            cap_match = re.search(\n",
    "                r'capacit[Ã©e]\\s*d[â€™\\'`]?accueil\\s*[:\\-]?\\s*(\\d+\\s*(?:chambres?|lits?|places?|chaises?))',\n",
    "                entry,\n",
    "                flags=re.IGNORECASE\n",
    "            )\n",
    "            if not cap_match:\n",
    "                cap_match = re.search(r'(\\d+\\s*(?:chambres?|lits?|places?|chaises?))', entry, flags=re.IGNORECASE)\n",
    "            capacity = cap_match.group(1).strip() if cap_match else \"\"\n",
    "\n",
    "            # === Logements ===\n",
    "            rooms_match = re.search(r'Nombre\\s+de\\s+logements\\s*[:\\-]?\\s*(.+)', entry)\n",
    "            rooms = rooms_match.group(1).split('\\n')[0].strip() if rooms_match else \"\"\n",
    "\n",
    "            # === Append ===\n",
    "            data.append({\n",
    "                \"Section\": section_name,\n",
    "                \"Type\": current_type,\n",
    "                \"Numero\": numero,\n",
    "                \"Ville\": ville,\n",
    "                \"Nom\": name,\n",
    "                \"Adresse\": address,\n",
    "                \"Email\": email,\n",
    "                \"Site web\": website,\n",
    "                \"CapacitÃ©\": capacity,\n",
    "                \"Logements\": rooms,\n",
    "                \"Page\": page_num\n",
    "            })\n",
    "\n",
    "# === CREATE DATAFRAME ===\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# === ADD FULL ADDRESS (for better geocoding accuracy) ===\n",
    "df[\"Full_Address\"] = df[\"Adresse\"].fillna('') + \", \" + df[\"Ville\"].fillna('')\n",
    "\n",
    "# === GOOGLE MAPS GEOCODING ===\n",
    "gmaps = googlemaps.Client(key=API_KEY)\n",
    "df[\"lat\"] = None\n",
    "df[\"long\"] = None\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Geocoding addresses\"):\n",
    "    full_address = row[\"Full_Address\"]\n",
    "    if pd.notna(full_address) and full_address.strip():\n",
    "        try:\n",
    "            geocode_result = gmaps.geocode(full_address)\n",
    "            if geocode_result:\n",
    "                location = geocode_result[0][\"geometry\"][\"location\"]\n",
    "                df.at[i, \"lat\"] = location[\"lat\"]\n",
    "                df.at[i, \"long\"] = location[\"lng\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error for '{full_address}': {e}\")\n",
    "            sleep(1)\n",
    "    sleep(0.1)\n",
    "\n",
    "# === SPLIT INTO MULTIPLE CSV FILES BY CHAPTER (1., 2., 3., etc.) ===\n",
    "df[\"Chapter\"] = df[\"Numero\"].apply(lambda x: x.split('.')[0] if isinstance(x, str) and '.' in x else None)\n",
    "\n",
    "# Mapping chapter numbers â†’ filenames\n",
    "chapter_filename_map = {\n",
    "    \"1\": \"hebergements_latlon.csv\",        # Structures d'hÃ©bergement\n",
    "    \"2\": \"logementsEncadres_latlon.csv\",   # Logements encadrÃ©s\n",
    "    \"3\": \"centresJour_latlon.csv\",         # Centres de jour\n",
    "    \"4\": \"activePlus_latlon.csv\",          # Clubs Aktiv Plus\n",
    "    \"7\": \"alarmes_latlon.csv\",             # Services tÃ©lÃ©alarme\n",
    "    \"8\": \"activities_latlon.csv\"           # Services activitÃ©s seniors\n",
    "    # Note: 5 and 6 omitted as per your extraction logic\n",
    "}\n",
    "\n",
    "for chapter, subdf in df.groupby(\"Chapter\"):\n",
    "    filename = chapter_filename_map.get(chapter, f\"chapter_{chapter}.csv\")  # default if unmapped\n",
    "    output_csv = os.path.join(output_folder, filename)\n",
    "    subdf.to_csv(output_csv, index=False, encoding=\"utf-8-sig\", sep=';', quoting=1)\n",
    "    print(f\"ðŸ’¾ Saved {output_csv} ({len(subdf)} rows)\")\n",
    "\n",
    "print(\"\\nâœ… All CSV files created successfully in:\")\n",
    "print(output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
